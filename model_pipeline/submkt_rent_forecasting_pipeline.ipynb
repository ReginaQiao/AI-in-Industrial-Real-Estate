{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69efc0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from darts.metrics import smape\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "import ast\n",
    "import multiprocessing as mp\n",
    "from datetime import datetime as dtm\n",
    "from typing import Optional, Sequence\n",
    "from darts.metrics import mape, mae\n",
    "from darts.utils.statistics import check_seasonality\n",
    "from darts.utils.statistics import plot_acf\n",
    "from darts.utils.statistics import plot_pacf\n",
    "from darts.models.forecasting.arima import ARIMA\n",
    "from darts.timeseries import TimeSeries as TS\n",
    "from sklearn.model_selection import ParameterGrid as PG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df617942",
   "metadata": {},
   "outputs": [],
   "source": [
    "pho_submkt = ['PHO037', 'PHO038', 'PHO039', 'PHO040', 'PHO041', 'PHO042',\n",
    "              'PHO043', 'PHO044', 'PHO045', 'PHO046', 'PHO047', 'PHO048',\n",
    "              'PHO049', 'PHO050', 'PHO051', 'PHO053', 'PHO054', 'PHO056',\n",
    "              'PHO057', 'PHO058', 'PHO059', 'PHO060', 'PHO061', 'PHO062',\n",
    "              'PHO063', 'PHO064', 'PHO065', 'PHO055']\n",
    "dal_submkt = ['DAL031', 'DAL034-DAL035-DAL041', 'DAL037-DAL038-DAL039-DAL040',\n",
    "              'DAL042-DAL043-DAL044-DAL045-DAL046', 'DAL047-DAL048', 'DAL049',\n",
    "              'DAL050-DAL051-DAL053-DAL054-DAL055', 'DAL052-DAL056',\n",
    "              'DAL057-FTW031', 'FTW029', 'FTW032-FTW033-FTW034-FTW039',\n",
    "              'FTW035-FTW036-FTW037-FTW040', 'FTW038-FTW041-FTW042-FTW043']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4483cf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_split_data_by_submarket(data, ntest):\n",
    "    train_data = pd.DataFrame()\n",
    "    test_data = pd.DataFrame()\n",
    "    submarkets = data['research_submkt_id'].unique()\n",
    "\n",
    "    for submarket in submarkets:\n",
    "        submarket_data = data[data['research_submkt_id'] == submarket]\n",
    "        train_submarket = submarket_data.iloc[:-ntest]\n",
    "        test_submarket = submarket_data.iloc[-ntest:]\n",
    "        train_data = pd.concat([train_data, train_submarket])\n",
    "        test_data = pd.concat([test_data, test_submarket])\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the Symmetric Mean Absolute Percentage Error (SMAPE) between two arrays.\n",
    "\n",
    "    Parameters:\n",
    "        y_true (array-like): Array of true values.\n",
    "        y_pred (array-like): Array of predicted values.\n",
    "\n",
    "    Returns:\n",
    "        float: SMAPE value.\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    \n",
    "    return np.mean(numerator / denominator) * 100\n",
    "\n",
    "\n",
    "def all_get_submkt_forecast(df, num_lags):\n",
    "    df_new = df[['date','research_submkt_id','real_hedonic_rent_submarket']]\n",
    "    df_new['date'] = pd.to_datetime(df_new['date'])\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    if num_lags is None:\n",
    "        num_lags = 36  \n",
    "\n",
    "    for lag in range(1, num_lags+1):\n",
    "        df_new['rent_{}months_ago'.format(lag)] = df_new.groupby('research_submkt_id')['real_hedonic_rent_submarket'].shift(lag)\n",
    "    df_new = df_new.dropna()\n",
    "    df_new = df_new.sort_values(['date', 'research_submkt_id']).reset_index(drop=True)\n",
    "    \n",
    "    df_sel = df[[\"date\", \n",
    "                 \"research_submkt_id\",\n",
    "                 \"real_market_level_rent\",\n",
    "                 \"gdp_histfc\",\n",
    "                 \"nominal_retail_sales_histfc\",\n",
    "                 \"employment_histfc\",\n",
    "                 \"real_ecommerce\",\n",
    "                 \"spread_3m10y\",\n",
    "                 \"real_retail_sales_ex_gas\",\n",
    "                 \"imports_us\",\n",
    "                 \"ecomm^2_pop\",\n",
    "                 \"weighted_pop_estimate_cryr\",\n",
    "                 \"weighted_hh_estimate_cryr\"]]\n",
    "\n",
    "    df_new = df_new.merge(df_sel,on=['date','research_submkt_id'],how='left')\n",
    "\n",
    "    X = df_new.iloc[:, [0, 1] + list(range(3, len(df_new.columns)))]\n",
    "    Y = df_new.iloc[:,:3]\n",
    "\n",
    "    Y_train, Y_test = all_split_data_by_submarket(Y,24)\n",
    "    y_train = Y_train.iloc[:,-1]\n",
    "    y_test = Y_test.iloc[:,-1]\n",
    "    X_train, X_test = all_split_data_by_submarket(X,24)\n",
    "    x_train = X_train.iloc[:,2:]\n",
    "    x_test = X_test.iloc[:,2:]\n",
    "\n",
    "\n",
    "    #param_grid = {\n",
    "    #    'n_estimators': [100, 150, 200, 250, 300],\n",
    "    #    'max_depth': [3, 4, 5],\n",
    "    #    'learning_rate': [0.15, 0.1, 0.01, 0.001]}\n",
    "    \n",
    "    param_grid = {\n",
    "    'n_estimators': [100, 150, 200, 250, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.15, 0.1, 0.01, 0.001],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3],\n",
    "    'colsample_bytree': [0.5, 0.75, 1],\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1],\n",
    "    'reg_lambda': [0, 0.1, 0.5, 1]}\n",
    "\n",
    "    #model = XGBRegressor()\n",
    "    #grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "    #grid_search.fit(x_train, y_train)\n",
    "\n",
    "    # Get the best parameters and best score\n",
    "    #best_params = grid_search.best_params_\n",
    "    #best_score = -grid_search.best_score_\n",
    "    #print(\"Best Parameters:\", best_params)\n",
    "    #print(\"Best Score (RMSE):\", best_score)\n",
    "\n",
    "    #best_model = XGBRegressor(**best_params)\n",
    "    #best_model.fit(x_train, y_train)\n",
    "    \n",
    "        \n",
    "    model = XGBRegressor()\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring=make_scorer(smape))\n",
    "    grid_search.fit(x_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = -grid_search.best_score_\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "    print(\"Best Score (SMAPE):\", best_score)\n",
    "\n",
    "    best_model = XGBRegressor(**best_params)\n",
    "    best_model.fit(x_train, y_train)\n",
    "    #importance = best_model.feature_importances_\n",
    "    #feature_importance_df = pd.DataFrame({'Attribute': x_train.columns, 'Importance': importance})\n",
    "\n",
    "    #feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    #plt.figure(figsize=(10, 6))\n",
    "    #plt.barh(feature_importance_df['Attribute'], feature_importance_df['Importance'])\n",
    "    #plt.xlabel('Importance')\n",
    "    #plt.ylabel('Attribute')\n",
    "    #plt.title('Feature Importance')\n",
    "    #plt.show()\n",
    "    \n",
    "    # using most important attributes to build new model\n",
    "    #selected_attributes = feature_importance_df['Attribute'].head(15).tolist()\n",
    "    #x_train_selected = x_train[selected_attributes]\n",
    "    #x_test_selected = x_test[selected_attributes]\n",
    "    #new_model = XGBRegressor(**best_params)\n",
    "    #new_model.fit(x_train_selected, y_train)\n",
    "\n",
    "\n",
    "    # predict\n",
    "    #y_pred = new_model.predict(x_test_selected)\n",
    "    y_pred = best_model.predict(x_test)\n",
    "\n",
    "\n",
    "    smape_value = smape(y_test, y_pred)\n",
    "    print(f\"SMAPE: {smape_value:.2f}%\")\n",
    "    \n",
    "    Y_test_pred = Y_test.copy()\n",
    "    Y_test_pred['y_pred'] = y_pred\n",
    "    \n",
    "    return Y_test_pred   #, feature_importance_df\n",
    "\n",
    "    \n",
    "def all_plot_submkt_forecast(Y_test_pred, submkt_id):\n",
    "\n",
    "    x = Y_test_pred[Y_test_pred['research_submkt_id']== submkt_id]['date']\n",
    "    y =  Y_test_pred[Y_test_pred['research_submkt_id']== submkt_id]['real_hedonic_rent_submarket']\n",
    "    y_pred =  Y_test_pred[Y_test_pred['research_submkt_id']== submkt_id]['y_pred']\n",
    "\n",
    "    plt.plot(x,y,label='test')\n",
    "    plt.plot(x,y_pred,label='pred')\n",
    "    plt.title('{} submkt_rent forecasting'.format(submkt_id))\n",
    "    plt.legend()\n",
    "\n",
    "    return plt.show()\n",
    "    \n",
    "    \n",
    "def get_single_smape(Y_test_pred, submkt_id):\n",
    "    \n",
    "    \n",
    "    y =  Y_test_pred[Y_test_pred['research_submkt_id']== submkt_id]['real_hedonic_rent_submarket']\n",
    "    y_pred =  Y_test_pred[Y_test_pred['research_submkt_id']== submkt_id]['y_pred']\n",
    "    \n",
    "    smp = smape(y,y1_pred)\n",
    "    \n",
    "    return smp\n",
    "\n",
    "    \n",
    "def get_whole_smape_df(Y_test_pred, submkt_list):\n",
    "    \n",
    "    smp_ls = []\n",
    "    for submkt in submkt_list:\n",
    "        y =  Y_test_pred[Y_test_pred['research_submkt_id']== submkt_id]['real_hedonic_rent_submarket']\n",
    "        y_pred =  Y_test_pred[Y_test_pred['research_submkt_id']== submkt_id]['y_pred']\n",
    "        smp = smape(y,y1_pred)\n",
    "        smp_ls.append(smp)\n",
    "    smp_dic = {'research_submkt_id':submkt_list,\n",
    "               'smape': smp_ls}\n",
    "    smp_df = pd.DataFrame(smp_dic)\n",
    "        \n",
    "    \n",
    "    return smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ca2b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
