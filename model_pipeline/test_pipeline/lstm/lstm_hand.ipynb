{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709e4cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from darts.metrics import smape\n",
    "from darts import TimeSeries\n",
    "from keras.layers import LSTM, Dense, BatchNormalization, Dropout, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e370a5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/zqiao/data_flake/imputed data/pho_t_data.csv',index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc49186",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf211ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[['date', 'research_submkt_id', 'real_hedonic_rent_submarket']]\n",
    "df_new['date'] = pd.to_datetime(df_new['date'])\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de9bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lags = 36\n",
    "for lag in range(1, num_lags + 1):\n",
    "    df_new[f'rent_{lag}months_ago'] = df_new.groupby('research_submkt_id')['real_hedonic_rent_submarket'].shift(lag)\n",
    "df_new = df_new.dropna()\n",
    "df_new = df_new.sort_values(['date', 'research_submkt_id']).reset_index(drop=True)\n",
    "    \n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cf5e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[['date',\n",
    "             'research_submkt_id',\n",
    "             'real_hedonic_rent_submarket',\n",
    "             'tech_employment_histfc',\n",
    "             'real_market_level_rent',\n",
    "             'nominal_earnings_byresidence_histfc',\n",
    "             'gdp_histfc',\n",
    "             'manufacturing_employment_histfc',\n",
    "             'population_histfc',\n",
    "             'real_bricks_and_mortar_retail_sales',\n",
    "             'compltn_rate',\n",
    "             'imports_us',\n",
    "             'nominal_retail_sales_histfc',\n",
    "             'real_retail_sales_ex_gas',\n",
    "             'unemployment_rate_histfc',\n",
    "             'median_sfh_sale_price_histfc',\n",
    "             'baa_credit_spreads',\n",
    "             \"nominal_retail_sales_histfc\",\n",
    "             \"employment_histfc\",\n",
    "             \"real_ecommerce\",\n",
    "             \"spread_3m10y\",\n",
    "             \"ecomm^2_pop\",\n",
    "             \"weighted_pop_estimate_cryr\",\n",
    "             \"weighted_hh_estimate_cryr\"]]\n",
    "\n",
    "#df_new = df_new.merge(df_sel, on=['date', 'research_submkt_id'], how='left')\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a152aa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[[\"date\", \n",
    "             \"research_submkt_id\",\n",
    "             'real_hedonic_rent_submarket',\n",
    "             \"real_market_level_rent\",\n",
    "             \"gdp_histfc\",\n",
    "             \"nominal_retail_sales_histfc\",\n",
    "             \"employment_histfc\",\n",
    "             \"real_ecommerce\",\n",
    "             \"spread_3m10y\",\n",
    "             \"real_retail_sales_ex_gas\",\n",
    "             \"imports_us\",\n",
    "             \"ecomm^2_pop\",\n",
    "             \"weighted_pop_estimate_cryr\",\n",
    "             \"weighted_hh_estimate_cryr\"]]\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42db768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_new.iloc[:, [0, 1] + list(range(3, len(df_new.columns)))]\n",
    "Y = df_new.iloc[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe81feb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764a95d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af338cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "Y_scaled = Y.copy()\n",
    "Y_scaled['real_hedonic_rent_submarket'] = scaler.fit_transform(Y['real_hedonic_rent_submarket'].values.reshape(-1, 1))\n",
    "X_scaled = X.copy()\n",
    "\n",
    "for i in range(2, X.shape[1]):\n",
    "    feature_values = X.iloc[:, i]\n",
    "    scaled_feature = scaler.fit_transform(feature_values.values.reshape(-1, 1))\n",
    "    X_scaled.iloc[:, i] = scaled_feature.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba9dc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db15ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c221e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_split_data_by_submarket(data, ntest, num_lags, submkt_id):\n",
    "\n",
    "    submarket_data = data[data['research_submkt_id'] == submkt_id]\n",
    "    seq_pred_train = submarket_data.iloc[-ntest-num_lags:-ntest]\n",
    "    train_data = submarket_data.iloc[:-ntest]\n",
    "    test_data = submarket_data.iloc[-ntest:]\n",
    "    seq_pred_train_data = pd.concat([seq_pred_train,test_data])\n",
    "    return train_data, test_data, seq_pred_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5317e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train, Y_test = all_split_data_by_submarket(Y_scaled,24)\n",
    "y_train = Y_train.iloc[:,-1]\n",
    "y_test = Y_test.iloc[:,-1]\n",
    "X_train, X_test = all_split_data_by_submarket(X_scaled,24)\n",
    "x_train = X_train.iloc[:,2:]\n",
    "x_test = X_test.iloc[:,2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7350954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train, Y_test, Y_seq_test = all_split_data_by_submarket(Y,24,12,'PHO037')\n",
    "y_train = Y_train.iloc[:,-1]\n",
    "y_test = Y_test.iloc[:,-1]\n",
    "y_seq_test = Y_seq_test.iloc[:,-1]\n",
    "X_train, X_test, X_seq_test = all_split_data_by_submarket(X,24,12,'PHO037')\n",
    "x_train = X_train.iloc[:,2:]\n",
    "x_test = X_test.iloc[:,2:]\n",
    "x_seq_test = X_seq_test.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef22dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape, x_seq_test.shape, y_seq_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e37d3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_seq_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee29ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, labels, num_lags):\n",
    "    x, y = [], []\n",
    "    for i in range(num_lags, len(data)):\n",
    "        x.append(data.iloc[i - num_lags:i, :].values)\n",
    "        y.append(labels.iloc[i])\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "x_train_seq, y_train_seq = create_sequences(x_train, y_train, 12)\n",
    "x_test_seq, y_test_seq = create_sequences(x_test, y_test, 12)\n",
    "x_test_seq_seq, y_test_seq_seq = create_sequences(x_seq_test, y_seq_test, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bf8afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_seq.shape, y_train_seq.shape, x_test_seq.shape, y_test_seq.shape, x_test_seq_seq.shape, x_test_seq_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2552e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f680c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(y_true, y_pred):\n",
    "    epsilon = 0.1  # Smoothing factor to avoid division by zero\n",
    "    denominator = K.abs(y_true) + K.abs(y_pred) + epsilon\n",
    "    diff = K.abs(y_true - y_pred) / denominator\n",
    "    return 2.0 * K.mean(diff, axis=-1)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(512, return_sequences=True), input_shape=(x_train_seq.shape[1], x_train_seq.shape[2])))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001, clipvalue=0.5)  # Adjust learning rate and gradient clipping as needed\n",
    "model.compile(loss='mean_squared_error', metrics=[smape]) # optimizer=optimizer, run_eagerly=True)\n",
    "\n",
    "# Define callbacks\n",
    "#early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=0.0001)\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train_seq, y_train_seq, epochs=500, batch_size=32,\n",
    "          validation_data=(x_test_seq, y_test_seq))     #, callbacks=[early_stopping, reduce_lr])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efa0977",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test_seq_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629cdaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72eaec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test['y_pred'] = y_pred\n",
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a54f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_plot_submkt_forecast(Y_test_pred, submkt_id):\n",
    "\n",
    "    x = Y_test_pred[Y_test_pred['research_submkt_id']== submkt_id]['date']\n",
    "    y =  Y_test_pred[Y_test_pred['research_submkt_id']== submkt_id]['real_hedonic_rent_submarket']\n",
    "    y_pred =  Y_test_pred[Y_test_pred['research_submkt_id']== submkt_id]['y_pred']\n",
    "    \n",
    "    plt.plot(x,y,label='test')\n",
    "    plt.plot(x,y_pred,label='pred')\n",
    "    plt.title('{} submkt_rent forecasting'.format(submkt_id))\n",
    "    plt.legend()\n",
    "\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e72255",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plot_submkt_forecast(Y_test, 'PHO037')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8fd6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = TimeSeries.from_series(Y_test['real_hedonic_rent_submarket'])\n",
    "y_p = TimeSeries.from_series(Y_test['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47aabea",
   "metadata": {},
   "outputs": [],
   "source": [
    "smape(y_t,y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77e24db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_get_submkt_forecast(df, num_lags):\n",
    "    df_new = df[['date', 'research_submkt_id', 'real_hedonic_rent_submarket']]\n",
    "    df_new['date'] = pd.to_datetime(df_new['date'])\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    if num_lags is None:\n",
    "        num_lags = 36\n",
    "\n",
    "    for lag in range(1, num_lags + 1):\n",
    "        df_new[f'rent_{lag}months_ago'] = df_new.groupby('research_submkt_id')['real_hedonic_rent_submarket'].shift(lag)\n",
    "    df_new = df_new.dropna()\n",
    "    df_new = df_new.sort_values(['date', 'research_submkt_id']).reset_index(drop=True)\n",
    "\n",
    "    df_sel = df[\n",
    "        ['date',\n",
    "         'research_submkt_id',\n",
    "         'base_sf',\n",
    "         'tech_employment_histfc',\n",
    "         'real_market_level_rent',\n",
    "         'nominal_earnings_byresidence_histfc',\n",
    "         'gdp_histfc',\n",
    "         'manufacturing_employment_histfc',\n",
    "         'population_histfc',\n",
    "         'real_bricks_and_mortar_retail_sales',\n",
    "         'compltn_rate',\n",
    "         'imports_us',\n",
    "         'nominal_retail_sales_histfc',\n",
    "         'real_retail_sales_ex_gas',\n",
    "         'unemployment_rate_histfc',\n",
    "         'median_sfh_sale_price_histfc',\n",
    "         'baa_credit_spreads']\n",
    "    ]\n",
    "\n",
    "    df_new = df_new.merge(df_sel, on=['date', 'research_submkt_id'], how='left')\n",
    "\n",
    "    X = df_new.iloc[:, [0, 1] + list(range(3, len(df_new.columns)))]\n",
    "    Y = df_new.iloc[:, :3]\n",
    "\n",
    "    Y_test_pred = pd.DataFrame(columns=Y.columns)\n",
    "\n",
    "    for submarket in df_new['research_submkt_id'].unique():\n",
    "        submarket_data = df_new[df_new['research_submkt_id'] == submarket]\n",
    "        submarket_X = X[X['research_submkt_id'] == submarket].iloc[:, 2:]\n",
    "        submarket_Y = Y[Y['research_submkt_id'] == submarket].iloc[:, -1]\n",
    "\n",
    "        # Prepare the data for the RNN model\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_data = scaler.fit_transform(submarket_Y.values.reshape(-1, 1))\n",
    "        x_scaled = np.zeros(submarket_X.shape)\n",
    "\n",
    "        for i in range(submarket_X.shape[1]):\n",
    "            feature_values = submarket_X.iloc[:, i].values.reshape(-1, 1)\n",
    "            scaled_feature = scaler.fit_transform(feature_values)\n",
    "            x_scaled[:, i] = scaled_feature.squeeze()\n",
    "\n",
    "        # Convert the data into sequences and labels\n",
    "        def create_sequences(data, labels, num_lags):\n",
    "            X, y = [], []\n",
    "            for i in range(num_lags, len(data)):\n",
    "                X.append(data[i - num_lags:i, :])\n",
    "                y.append(labels[i])\n",
    "            return np.array(X), np.array(y)\n",
    "\n",
    "        X_seq, y_seq = create_sequences(x_scaled, scaled_data, num_lags)\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        train_size = int(len(X_seq) * 0.8)  # 80% train, 20% validation\n",
    "        X_train, y_train = X_seq[:train_size], y_seq[:train_size]\n",
    "        X_val, y_val = X_seq[train_size:], y_seq[train_size:]\n",
    "\n",
    "        # Build the RNN model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "        model.add(LSTM(50))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_val, y_val), verbose=0)\n",
    "\n",
    "        # Make predictions\n",
    "        x_test = submarket_X.iloc[-num_lags:]\n",
    "        x_test_scaled = np.zeros_like(x_test.values)\n",
    "\n",
    "        for i in range(x_test.shape[1]):\n",
    "            feature_values = x_test.iloc[:, i].values.reshape(-1, 1)\n",
    "            scaled_feature = scaler.transform(feature_values)\n",
    "            x_test_scaled[:, i] = scaled_feature.squeeze()\n",
    "\n",
    "        x_test_scaled = x_test_scaled.reshape(1, num_lags, -1)\n",
    "        y_pred_scaled = model.predict(x_test_scaled)\n",
    "        y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "\n",
    "        # Append predictions to Y_test_pred\n",
    "        submarket_Y_pred = pd.DataFrame(submarket_Y.iloc[-len(y_pred):].values.reshape(-1, 1), columns=['real_hedonic_rent_submarket'])\n",
    "        submarket_Y_pred['y_pred'] = y_pred\n",
    "        Y_test_pred = pd.concat([Y_test_pred, submarket_Y_pred], ignore_index=True)\n",
    "\n",
    "    return Y_test_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525d102f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbacedf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Call the function\n",
    "df = pd.read_csv('/home/zqiao/data_flake/imputed data/dal_t_data.csv',index_col=0)  # Replace with your data file\n",
    "num_lags = 36  # Adjust as needed\n",
    "Y_test_pred = all_get_submkt_forecast(df, num_lags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042236d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
