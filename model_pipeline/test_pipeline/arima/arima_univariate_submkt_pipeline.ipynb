{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1288aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "from datetime import datetime as dtm\n",
    "from typing import Optional, Sequence\n",
    "\n",
    "from darts.metrics import mape, mae\n",
    "\n",
    "from darts.utils.statistics import check_seasonality\n",
    "from darts.utils.statistics import plot_acf\n",
    "from darts.utils.statistics import plot_pacf\n",
    "\n",
    "from darts.models.forecasting.varima import VARIMA\n",
    "from darts.models.forecasting.arima import ARIMA\n",
    "\n",
    "from darts.timeseries import TimeSeries as TS\n",
    "from sklearn.model_selection import ParameterGrid as PG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f2fa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the Symmetric Mean Absolute Percentage Error (SMAPE) between two arrays.\n",
    "\n",
    "    Parameters:\n",
    "        y_true (array-like): Array of true values.\n",
    "        y_pred (array-like): Array of predicted values.\n",
    "\n",
    "    Returns:\n",
    "        float: SMAPE value.\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    \n",
    "    return np.mean(numerator / denominator) * 100\n",
    "\n",
    "def load_training_data(market_name):\n",
    "    #df = pd.read_csv('/home/zqiao/data_flake/imputed data/{}_data.csv'.format(market_name), index_col=0)\n",
    "    df = pd.read_csv('/home/zqiao/data_flake/imputed data/pho_t_data.csv',index_col=0)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.set_index('date')\n",
    "    return df\n",
    "\n",
    "def train_auto_varima_mp(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    X_test,\n",
    "    Y_test,\n",
    "    min_d,\n",
    "    max_d,\n",
    "    trends,\n",
    "    max_p,\n",
    "    min_p,\n",
    "    max_q,\n",
    "    min_q,\n",
    "    ntest\n",
    "):\n",
    "    if trends is None:\n",
    "        trends = [None]\n",
    "\n",
    "    param_vals = {\n",
    "        \"p\": [i for i in range(min_p, max_p + 1)],\n",
    "        \"d\": [i for i in range(min_d, max_d + 1)],\n",
    "        \"q\": [i for i in range(min_q, max_q + 1)],\n",
    "        \"trend\": trends,\n",
    "    }\n",
    "    param_grid = list(PG(param_vals))\n",
    "    num_params = len(param_grid)\n",
    "\n",
    "    results = {}\n",
    "    pool = mp.Pool(processes=mp.cpu_count())\n",
    "    for idx, params in enumerate(param_grid):\n",
    "        print(f\"training model {idx}/{num_params-1}: {params}\")\n",
    "\n",
    "        result = pool.apply_async(\n",
    "            run_varima_experiment,\n",
    "            kwds={\n",
    "                \"X_train\": X_train,\n",
    "                \"Y_train\": Y_train,\n",
    "                \"X_test\": X_test,\n",
    "                \"Y_test\": Y_test,\n",
    "                \"params\": params,\n",
    "                \"ntest\": ntest\n",
    "            },\n",
    "        )\n",
    "        params = str(params)\n",
    "        results[params] = result\n",
    "\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    for key, value in results.items():\n",
    "        if value.get() is not None:\n",
    "            results[key] = value.get()\n",
    "    else:\n",
    "            results[key] = 0\n",
    "    res_df = pd.DataFrame.from_dict(results, orient='index', columns=['metric_val'])\n",
    "    res_df = res_df.sort_values('metric_val', ascending=True)\n",
    "    best_params = res_df.index.values[1]\n",
    "    best_params = ast.literal_eval(best_params)\n",
    "    p = best_params['p']\n",
    "    d = best_params['d']\n",
    "    q = best_params['q']\n",
    "    trend = best_params['trend']\n",
    "\n",
    "\n",
    "    return p,d,q,trend, res_df\n",
    "\n",
    "\n",
    "\n",
    "def run_varima_experiment(X_train, X_test, Y_train, Y_test, params, ntest):\n",
    "    \n",
    "    model = train_varima_model(X_train=X_train, Y_train=Y_train, **params)\n",
    "    metric_val = evaluate_varima_model(model, X_test, Y_test, ntest)\n",
    "\n",
    "    return metric_val\n",
    "\n",
    "def train_varima_model(X_train, Y_train, p, d, q, trend):\n",
    "    \n",
    "    if d not in [0, 1]:\n",
    "        raise ValueError(f\"d can only take on values 0 or 1\")\n",
    "\n",
    "    model = ARIMA(p=p, d=d, q=q, trend=trend)\n",
    "    model.fit(Y_train, future_covariates=X_train)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def evaluate_varima_model(model, \n",
    "                          X_test, \n",
    "                          Y_test, \n",
    "                          ntest):\n",
    "\n",
    "    pred = model.predict(ntest, future_covariates=X_test)\n",
    "    pred_transfer = pred.pd_dataframe()\n",
    "    Y_test_transfer = Y_test.pd_dataframe()\n",
    "    pred_transfer['real_hedonic_rent_submarket'][0] = Y_test_transfer['real_hedonic_rent_submarket'][0]\n",
    "    pred_transfer['real_hedonic_rent_submarket'] = pred_transfer['real_hedonic_rent_submarket'].cumsum()\n",
    "    pred_new = TS.from_dataframe(pred_transfer)\n",
    "    \n",
    "    Y_test_series = Y_test_transfer['real_hedonic_rent_submarket']\n",
    "    pred_series = pred_transfer['real_hedonic_rent_submarket']\n",
    "    err = smape(Y_test_series, pred_series)\n",
    "\n",
    "    return err\n",
    "\n",
    "\n",
    "def run_varima_pipeline(market_name: str = None,\n",
    "                        submkt_id: Optional[Sequence[str]] = None, \n",
    "                        target = \"real_hedonic_rent_submarket\",\n",
    "                        features: list = None,\n",
    "                        target_rolling: bool = None,\n",
    "                        a_shift: bool = None,\n",
    "                        ntest: int = None,\n",
    "                        nlag: int = None,\n",
    "                        rol_num: int = None,\n",
    "                        min_d: int = None,\n",
    "                        max_d: int = None,\n",
    "                        trends: Optional[Sequence[str]] = None,\n",
    "                        max_p: int = None,\n",
    "                        min_p: int = None,\n",
    "                        max_q: int = None,\n",
    "                        min_q: int = None):\n",
    "    \n",
    "    if market_name is None:\n",
    "        market_name = 'pho'\n",
    "    \n",
    "    if submkt_id is None:\n",
    "        submkt_id = 'PHO037'\n",
    "\n",
    "    df = load_training_data(market_name)\n",
    "\n",
    "    grouped_df = df.groupby('research_submkt_id')\n",
    "    for submkt, submkt_group in grouped_df:\n",
    "        if submkt == submkt_id:\n",
    "            submkt_df = submkt_group\n",
    "    \n",
    "    if ntest is None:\n",
    "        ntest = 12\n",
    "    \n",
    "    if nlag is None:\n",
    "        nlag = 6\n",
    "        \n",
    "    if features is None:\n",
    "        features = [\n",
    "            \"real_market_level_rent\",\n",
    "            \"gdp_histfc\",\n",
    "            \"nominal_retail_sales_histfc\",\n",
    "            \"employment_histfc\",\n",
    "            \"real_ecommerce\",\n",
    "            \"spread_3m10y\",\n",
    "            \"real_retail_sales_ex_gas\",\n",
    "            \"imports_us\",\n",
    "            \"ecomm^2_pop\",\n",
    "            \"weighted_pop_estimate_cryr\",\n",
    "            \"weighted_hh_estimate_cryr\"]\n",
    "    \n",
    "    pdf = submkt_df[[target] + features].copy()\n",
    "    pdf[\"real_market_level_rent\"] = pdf[\"real_market_level_rent\"].diff()\n",
    "    if a_shift:\n",
    "        #pdf[\"avrate\"] = pdf[\"avrate\"].shift(nlag)\n",
    "        #pdf[\"real_market_level_rent\"] = pdf[\"real_market_level_rent\"].shift(nlag)\n",
    "        for col in features:\n",
    "            pdf[col] = pdf[col].shift(nlag)\n",
    "\n",
    "    if target_rolling:\n",
    "        pdf[target] = pdf[target].rolling(rol_num).mean()\n",
    "   \n",
    "    pdf = pdf.dropna()\n",
    "    X = TS.from_dataframe(pdf[features])\n",
    "    Y = TS.from_dataframe(pdf[[target]])\n",
    "    X_train, X_test = X[:-ntest], X[-ntest:]\n",
    "    Y_train, Y_test = Y[:-ntest], Y[-ntest:]\n",
    "    \n",
    "    p,d,q,trend,res_df = train_auto_varima_mp(\n",
    "        X_train = X_train,\n",
    "        Y_train = Y_train,\n",
    "        X_test = X_test,\n",
    "        Y_test = Y_test,\n",
    "        min_d = min_d,\n",
    "        max_d = max_d,\n",
    "        trends = trends,\n",
    "        max_p = max_p,\n",
    "        min_p = min_p,\n",
    "        max_q = max_q,\n",
    "        min_q = min_q,\n",
    "        ntest = ntest)\n",
    "\n",
    "    print('This is the best params of varima model: p: ',p,', d: ',d,' q: ',q,' trend: ',trend )\n",
    "    \n",
    "    \n",
    "\n",
    "    return X, Y, X_train, Y_train, X_test, Y_test, p, d, q, trend, res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0ae811",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, X_train, Y_train, X_test, Y_test,p, d, q, trend, res_df = run_varima_pipeline(market_name = 'pho',\n",
    "                                                       submkt_id = 'PHO038', \n",
    "                                                       target = 'real_hedonic_rent_submarket',\n",
    "                                                       features = None,\n",
    "                                                       target_rolling = False,\n",
    "                                                       a_shift = False,\n",
    "                                                       ntest = 24,\n",
    "                                                       nlag = 3,\n",
    "                                                       rol_num = 6,                      \n",
    "                                                       min_d = 0,\n",
    "                                                       max_d = 0,\n",
    "                                                       trends = [None,'ct','t'],\n",
    "                                                       max_p = 5,\n",
    "                                                       min_q = 1,\n",
    "                                                       max_q = 5,\n",
    "                                                       min_p = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b193071",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(Y, m=None, max_lag=24, alpha=0.01, fig_size=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4948841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(Y, m=None, max_lag=24, alpha=0.01, fig_size=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f12a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3de4460",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = train_varima_model(X_train, Y_train, p, d, q, trend)\n",
    "Y_pred = final_model.predict(24, future_covariates=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb1179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Y_pred.plot(label='pred')\n",
    "Y_test.plot(label='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f76b7c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bd54ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892c6a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c548783",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
